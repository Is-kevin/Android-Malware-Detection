'''
蚂蚁分组独立搜索，每隔一段周期沟通信息素
'''

import math
import numpy as np
import random
from myaco_groups import ACO, Graph
import pandas as pd
import matplotlib.pyplot as plt
from share import topN, feature_path, label_path, feature_imp_vec_path, featureSelectNum, gama
from sklearn.ensemble import RandomForestClassifier
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
import datetime

feature = pd.read_csv(feature_path, sep=' ', header=None).values
label = pd.read_csv(label_path, sep=' ', header=None).values.ravel()
featureImpo = np.zeros((topN, 5))


# 生成相似性矩阵
def compute_similarity():
    ImportanceVec = []
    lines = open(feature_imp_vec_path, 'r').readlines()
    out = open(feature_imp_vec_path, 'w')
    for line in lines:
        out.write(str(line.replace('[', '').replace(']', '')))

    lines = open(feature_imp_vec_path, 'r').readlines()
    for line in lines:
        ImportanceVec.append(line.strip())
    # 文件中存的是str，需要将str转float放进数组再重新组成矩阵
    for i in range(len(ImportanceVec)):
        mystr = ImportanceVec[i].split(',')
        for j in range(len(mystr)):
            num = float(mystr[j])
            featureImpo[i][j] = num

    similarity = cosine_similarity(featureImpo)
    print("相似性矩阵计算完成")
    return similarity


def ActivationFunction(a):  # tanh Function
    e = 2.671
    expo1 = e ** a
    expo2 = e ** -a
    val = (expo1 - expo2) / (expo1 + expo2)
    return val


def compute_etatable_matrix(similarity):
    eta = np.zeros([15, topN, topN])
    # eta = np.zeros([20, topN, topN])
    # score_mean = np.zeros((topN, 20))
    score_mean = np.zeros((topN, 15))

    for i in range(topN):
        index = 0
        for j in range(5):
            score_mean[i][index] = featureImpo[i][j]
            index += 1

    for i in range(topN):
        index = 5
        for j in range(4):
            for k in range(j + 1, 5):
                score_mean[i][index] = (featureImpo[i][j] + featureImpo[i][k]) / 2
                index += 1

    # for i in range(topN):
    #     index = 10
    #     for j in range(3):
    #         for k in range(j+1, 4):
    #             for l in range(k+1, 5):
    #                 score_mean[i][index] = (featureImpo[i][j] + featureImpo[i][k] + featureImpo[i][l]) / 3
    #                 index += 1

    # for i in range(20):
    for i in range(15):
        for j in range(topN):
            for k in range(topN):
                # 使用tanh函数将启发值压缩到[0,1]区间
                # 有些相似度很低的会导致分母变为0，其实就可以当成他们没有相似度，只考虑重要性分数
                # if similarity[j][k] ** gama != 0:
                #     eta[i][j][k] = ActivationFunction(score_mean[k][i] / (similarity[j][k] ** gama))
                # else:
                #     eta[i][j][k] = ActivationFunction(score_mean[k][i])
                eta[i][j][k] = score_mean[k][i] * (1 - similarity[j][k]) ** gama

    return eta


def update_etatable_weight(weight, each_type_accuracy):
    '''
    每一轮迭代后，根据准确率更新15组启发式信息的权重
    '''
    # for i in range(20):
    for i in range(15):
        if each_type_accuracy[i] > 0:
            weight[i] = 0.5 * math.log2(each_type_accuracy[i] / float(1 - each_type_accuracy[i]))
    # 归一化
    sumw = sum(weight)
    for i in range(15):
        weight[i] = weight[i] / sumw
    print("权重数组：")
    print(weight)


def main():
    path = []
    bestpath = []
    # weight = [0.05] * 20
    weight = [0.066] * 15
    # each_type_accuracy = [0.0] * 20
    each_type_accuracy = [0.0] * 15
    bestacc = 0
    acc4plt = []
    acc = 0
    f1 = 0
    generations = 0
    similarity = compute_similarity()
    etatable = compute_etatable_matrix(similarity)
    # ant_count, generations, alpha, beta, rho, q, strategy, similarity
    aco = ACO(100, 200, 1.0, 10.0, 0.5, 10, 3, similarity)  # 代码逻辑改动，这里传进去的代数其实没用

    graphs = [Graph() for i in range(5)]

    for gen in range(200):
        genstart = datetime.datetime.now()
        update_etatable_weight(weight, each_type_accuracy)
        # 由于分组要独立搜索，所以graph也要独立开来
        path, acc, f1, generations, each_type_accuracy, graph, ant = aco.solve(graphs, etatable, weight, each_type_accuracy)
        if acc > bestacc:
            bestacc = acc
            bestpath = path
        acc4plt.append(bestacc)
        genend = datetime.datetime.now()
        print('第{}代准确率：{}'.format(gen, acc))
        print('第{}代f1_score：{}'.format(gen, f1))
        print('第{}代用时：{}'.format(gen, genend - genstart))
        print("=============================================")

        if gen != 0 & gen % 29 == 0:
            aco._update_pheromone2(graph, ant)

        if gen == 199:
            print("astarr")
            print(acc4plt)
            idx = np.arange(200)
            plt.title("astringency")
            plt.plot(idx, acc4plt, linestyle='-', marker='o', markersize=5)
            plt.savefig('print/my-astringency')
            plt.show()
    return bestpath, bestacc, f1, acc4plt


if __name__ == '__main__':
    start = datetime.datetime.now()
    pathbest, accuary, f1score, acc4plt = main()
    end = datetime.datetime.now()
    # print('使用所有特征进行分类的准确率：{}'.format(initacc))
    print('特征选择后准确率: {}'.format(accuary))
    print('特征选择后f1_score: {}'.format(f1score))

    with open("tmpfile/result", 'a+', encoding="utf-8") as f:
        f.write("featureSelectNum: " + str(featureSelectNum) + '\n')
        f.write("accuracy: " + str(accuary) + '\n')
        f.write("f1_score: " + str(f1score) + '\n')
        f.write("maintime: " + str((end - start)) + '\n')
        f.write("acc4plt: " + str(acc4plt) + '\n')
        f.write("==========================================================================================" + '\n')
